# ALEXANDRIA SYSTEM ANALYSIS - COMPLETE STATE REPORT

**Analysis Date**: 2025-10-19
**Current Status**: Phases 0-7 Complete (70% of MVP)
**Files**: 59 Python modules, 15 configs, 24 test files

---

## EXECUTIVE SUMMARY

### What Alexandria Is
A podcast generation pipeline that transforms knowledge sources (NotebookLM exports, PDFs, documents) into professional podcast audio with configurable personas, multiple output formats, and comprehensive quality control.

### Current State
- **7 of 9 phases complete**
- **~60 Python modules** implemented
- **10 configurable personas**
- **Full QC suite** operational
- **Mock TTS/ASR** (needs real implementation)

### What Works Right Now
‚úÖ End-to-end pipeline from source ‚Üí script ‚Üí mock audio
‚úÖ Multi-persona script generation (10 personas)
‚úÖ Quality control and validation
‚úÖ Export packaging and RSS generation
‚úÖ Length mode variants (full/condensed/topic_focus)
‚úÖ Promo clip extraction and stem packaging

### What's Missing
‚ùå Real TTS engines (F5-TTS, Piper)
‚ùå Real ASR (Whisper integration)
‚ùå Actual audio processing (ffmpeg operations)
‚ùå Vector embeddings (sentence-transformers)
‚ùå RAG retrieval (Qdrant)
‚ùå End-to-end integration tests
‚ùå Docker deployment
‚ùå API/Worker services

---

## SYSTEM ARCHITECTURE

### Pipeline Flow

```
INPUT ‚Üí KNOWLEDGE ORG ‚Üí INGESTION ‚Üí SEGMENTATION ‚Üí PLANNING ‚Üí
WRITING ‚Üí GROUNDING ‚Üí TTS ‚Üí MASTERING ‚Üí QC ‚Üí PUBLISHING ‚Üí OUTPUT
```

### Detailed Flow

**Phase K: Knowledge Organization**
```
PDFs/Docs ‚Üí Curator ‚Üí Normalizer ‚Üí Deduplicator ‚Üí Scorer ‚Üí Knowledge Packs
```

**Phase 1: Ingestion & ASR**
```
Audio ‚Üí Watcher ‚Üí ffmpeg Normalize ‚Üí Whisper ‚Üí Language Detect ‚Üí Transcript
```

**Phase 2: Segmentation & Embeddings**
```
Transcript ‚Üí Segmenter ‚Üí Embedder ‚Üí FAISS Indexer ‚Üí Graph Builder ‚Üí Segments
```

**Phase 3: Planning & Writing**
```
Segments ‚Üí Outliner ‚Üí Selector ‚Üí Scripter (w/ Persona) ‚Üí Continuity Check ‚Üí Script
```

**Phase 4: Grounding Audit**
```
Sources + Script ‚Üí RAG Indexer ‚Üí Auditor ‚Üí Groundedness Report
```

**Phase 5: TTS & Mastering**
```
Script ‚Üí TTS Synthesizer ‚Üí Batch Stems ‚Üí Mixer ‚Üí Audio Exporter ‚Üí Final Mix
```

**Phase 6: Variants**
```
Segments ‚Üí Promo Clipper ‚Üí Highlight Clips
Stems ‚Üí Stem Packager ‚Üí Clipchamp Export
```

**Phase 7: QC & Publishing**
```
Mix ‚Üí RAGAS/WER/LUFS Checks ‚Üí QC Runner ‚Üí RSS Feed + Manifest ‚Üí Publish
```

---

## PHASE-BY-PHASE STATUS

### ‚úÖ Phase 0: Scaffolding - COMPLETE
**Files**: Makefile, requirements.txt, docker-compose.yml, configs/*, schemas/*

**Capabilities:**
- Complete directory structure
- Make targets for all phases
- Configuration templates (hosts, mastering, retrieval, output_menu)
- JSON schemas (manifest, segment, qc_report)
- Config validation script

**Gaps:**
- Docker services not tested
- Some dependencies not installed

---

### ‚úÖ Phase K: Knowledge Organization - COMPLETE (MOCK)
**Location**: `app/packages/knowledge/`
**Files**: curator.py, normalizer.py, deduplicator.py, scorer.py, pack_builder.py

**What Works:**
- File cataloging with SHA256
- CSV-based tracking
- Knowledge pack creation by topic/language
- Quality scoring heuristics

**What's Mock:**
- GROBID/Unstructured extraction (needs Docker services)
- MinHash deduplication (needs datasketch library)

**To Make Real:**
1. Install GROBID via Docker
2. Add datasketch library
3. Test with real PDFs

---

### ‚úÖ Phase 1: Ingestion & ASR - COMPLETE (MOCK ASR)
**Location**: `app/packages/ingest/`, `app/packages/asr/`
**Files**: watcher.py, normalizer.py, transcriber.py, language_detector.py

**What Works:**
- Format validation (.mp3, .wav, .m4a, .mp4)
- Manifest generation
- Language detection (langdetect)

**What's Mock:**
- ffmpeg normalization (creates placeholder files)
- Whisper transcription (returns mock text)

**To Make Real:**
1. Install faster-whisper
2. Implement real ffmpeg calls
3. Test with audio files

**Critical Priority**: ‚ö†Ô∏è HIGH - Blocks real pipeline testing

---

### ‚úÖ Phase 2: Segmentation & Embeddings - COMPLETE (MOCK EMBEDDINGS)
**Location**: `app/packages/segment/`, `app/packages/embed/`, `app/packages/graph/`
**Files**: segmenter.py, embedder.py, indexer.py, builder.py

**What Works:**
- Segment creation (20-60s chunks)
- Schema validation
- Similarity graph computation
- Duplicate detection (>0.90 threshold)

**What's Mock:**
- Sentence embeddings (uses random vectors)
- FAISS indexing (creates placeholder)

**To Make Real:**
1. Install sentence-transformers
2. Install faiss-cpu
3. Load bge-large-en model
4. Test retrieval

**Critical Priority**: ‚ö†Ô∏è MEDIUM - Affects content quality

---

### ‚úÖ Phase 3: Planning & Writing - COMPLETE
**Location**: `app/packages/planner/`, `app/packages/writer/`, `app/packages/continuity/`
**Files**: outliner.py, selector.py, scripter.py, checker.py, persona_loader.py

**What Works:**
‚úÖ Length modes (full=60min, condensed=20min, topic_focus=10min)
‚úÖ Segment selection with duplicate avoidance
‚úÖ 10 personas (academic, casual, coach, educator, enthusiast, journalist, mentor, philosopher, storyteller, technical)
‚úÖ Persona auto-discovery from configs/personas/
‚úÖ Lexical preference application
‚úÖ output_menu.yaml integration

**What's Mock:**
- LLM-based rewriting (uses simple string replacement)
- Continuity checking (placeholder logic)

**To Make Real (Optional):**
1. Add OpenAI/Anthropic API for real style transfer
2. Implement entity/claim extraction for continuity

**Priority**: üîµ LOW - Current implementation functional

---

### ‚úÖ Phase 4: Grounding Audit - COMPLETE (MOCK RAG)
**Location**: `app/packages/rag_audit/`
**Files**: source_indexer.py, auditor.py

**What Works:**
- Report generation framework
- Groundedness scoring structure

**What's Mock:**
- Qdrant indexing (no vector DB)
- RAG retrieval (mock scores)

**To Make Real:**
1. Install qdrant-client
2. Run Qdrant via Docker
3. Index sources with embeddings
4. Implement retrieval

**Priority**: ‚ö†Ô∏è MEDIUM - Important for quality, but not blocking

---

### ‚úÖ Phase 5: TTS & Mastering - COMPLETE (MOCK TTS/AUDIO)
**Location**: `app/packages/tts/`, `app/packages/mastering/`, `app/packages/exporters/`
**Files**: synthesizer.py, batch_synth.py, mixer.py, audio_exporter.py, notes_generator.py

**What Works:**
- Deterministic file generation
- Voice caching framework
- Pipeline orchestration
- Show notes generation

**What's Mock:**
- TTS synthesis (creates empty WAV files)
- LUFS normalization (no actual processing)
- ffmpeg operations (file copies only)
- Chapter markers (metadata only)

**To Make Real:**
1. Install F5-TTS or Piper
2. Install ffmpeg-python
3. Install pyloudnorm
4. Implement real audio concatenation
5. Implement LUFS measurement

**Critical Priority**: üî¥ HIGHEST - Blocks audio output

---

### ‚úÖ Phase 6: Variants & Customization - COMPLETE
**Location**: `app/packages/exporters/`, `configs/personas/`
**Files**: promo_clipper.py, stem_packager.py, 10 persona configs

**What Works:**
‚úÖ Promo clip extraction (30-90s highlights)
‚úÖ Scoring algorithm (duration/density/position)
‚úÖ Stem packaging with Clipchamp naming
‚úÖ Speaker detection from script
‚úÖ 10 diverse personas
‚úÖ Unlimited persona support
‚úÖ Persona discovery CLI

**No Gaps**: Fully functional!

---

### ‚úÖ Phase 7: QC & Publishing - COMPLETE (MOCK METRICS)
**Location**: `app/packages/eval/`, `app/packages/exporters/`
**Files**: ragas_scorer.py, wer_calculator.py, lufs_checker.py, qc_runner.py, rss_generator.py, manifest_writer.py

**What Works:**
‚úÖ QC orchestration (5 check types)
‚úÖ Pass/fail reporting
‚úÖ WER calculation (Levenshtein distance)
‚úÖ RSS feed generation
‚úÖ Export manifest

**What's Mock:**
- RAGAS library integration
- Actual LUFS measurement
- Real TTS transcription for WER

**To Make Real:**
1. Install ragas library
2. Connect to real LUFS checker
3. Use real TTS output for WER

**Priority**: üîµ LOW - Framework solid, metrics can be upgraded later

---

### ‚ùå Phase 8: Multilingual - NOT STARTED
**Tasks:**
- T8.01: NLLB-200 translator
- T8.02: Multilingual TTS voices

**Priority**: üü¢ FUTURE - V1 enhancement

---

### ‚ùå Phase 9: Integration & Handoff - NOT STARTED
**Tasks:**
- T9.01: run_show.sh wrapper script
- T9.02: Golden fixture end-to-end tests
- T9.03: README documentation

**Priority**: ‚ö†Ô∏è HIGH - Needed for MVP delivery

---

## DEPENDENCY STATUS

### Installed ‚úÖ
- pydantic (2.0+)
- yaml, json (config)
- pytest, hypothesis (testing)
- typer (CLI)
- datamodel-code-generator

### Missing ‚ùå (Critical)
```bash
# ASR
faster-whisper

# Embeddings & Vector Search
sentence-transformers
faiss-cpu
qdrant-client

# Audio Processing
ffmpeg-python
pyloudnorm

# TTS
# F5-TTS (external repo)
# Piper (external binary)

# RAG Evaluation
ragas

# Knowledge Processing
datasketch
grobid-client
unstructured

# Worker System
celery
redis
```

### Install Command (Partial)
```bash
pip install faster-whisper sentence-transformers faiss-cpu qdrant-client \
    ffmpeg-python pyloudnorm ragas datasketch unstructured celery redis
```

**Note**: F5-TTS and Piper require separate installation

---

## INFRASTRUCTURE STATUS

### Docker Services (docker-compose.yml)
| Service | Status | Purpose |
|---------|--------|---------|
| api (FastAPI) | ‚ùå Stub only | REST API |
| worker (Celery) | ‚ùå Stub only | Async tasks |
| qdrant | ‚ùå Not configured | Vector DB |
| grobid | ‚ùå Not configured | PDF extraction |
| redis | ‚ùå Not configured | Task queue |

**To Deploy:**
```bash
docker-compose up -d
# Then verify services
docker-compose ps
```

---

## TEST COVERAGE

### Current Tests (37 total)
- ‚úÖ Phase 5 TTS modules (12 tests)
- ‚úÖ Generated models (Hypothesis - 11 tests)
- ‚úÖ API orchestration (1 test)
- ‚úÖ Integration (1 test)
- ‚ùå Phases 1-4 (no tests)
- ‚ùå Phases 6-7 (no tests)

### Coverage Estimate: ~30%

### Missing Tests
- Phase 1: ASR pipeline
- Phase 2: Embeddings/graph
- Phase 3: Planning/writing
- Phase 4: RAG audit
- Phase 6: Exporters
- Phase 7: QC checks
- End-to-end: Golden fixtures

---

## BUILD ROADMAP FROM HERE

### MILESTONE 1: Make Audio Real (HIGHEST PRIORITY)
**Goal**: Get one real audio file out

**Tasks:**
1. ‚úÖ Install faster-whisper
2. ‚úÖ Implement real transcription in transcriber.py
3. ‚úÖ Install F5-TTS or Piper
4. ‚úÖ Implement real TTS in synthesizer.py
5. ‚úÖ Install ffmpeg
6. ‚úÖ Implement real mixing in mixer.py
7. ‚úÖ Install pyloudnorm
8. ‚úÖ Implement LUFS measurement
9. ‚úÖ Test end-to-end: audio ‚Üí transcript ‚Üí script ‚Üí TTS ‚Üí mix

**Deliverable**: One real podcast episode from test audio

**Estimated Effort**: 2-3 days

---

### MILESTONE 2: Make Embeddings Real (HIGH PRIORITY)
**Goal**: Enable semantic search and RAG

**Tasks:**
1. ‚úÖ Install sentence-transformers
2. ‚úÖ Load bge-large-en model
3. ‚úÖ Implement real embeddings in embedder.py
4. ‚úÖ Install faiss-cpu
5. ‚úÖ Build real FAISS index in indexer.py
6. ‚úÖ Install Qdrant via Docker
7. ‚úÖ Implement source indexing in source_indexer.py
8. ‚úÖ Implement RAG retrieval in auditor.py
9. ‚úÖ Test: sources ‚Üí embeddings ‚Üí RAG ‚Üí groundedness score

**Deliverable**: Working RAG grounding verification

**Estimated Effort**: 1-2 days

---

### MILESTONE 3: Complete Integration (MEDIUM PRIORITY)
**Goal**: End-to-end pipeline working

**Tasks:**
1. ‚úÖ Write run_show.sh wrapper (Phase 9)
2. ‚úÖ Create golden fixture (Phase 9)
3. ‚úÖ Write end-to-end test (Phase 9)
4. ‚úÖ Test full pipeline: input ‚Üí audio output
5. ‚úÖ Fix any integration issues
6. ‚úÖ Document in README (Phase 9)

**Deliverable**: Documented, tested pipeline

**Estimated Effort**: 2 days

---

### MILESTONE 4: Deploy Services (MEDIUM PRIORITY)
**Goal**: Docker deployment working

**Tasks:**
1. ‚úÖ Configure Qdrant service
2. ‚úÖ Configure GROBID service
3. ‚úÖ Configure Redis
4. ‚úÖ Implement FastAPI routes in api/main.py
5. ‚úÖ Implement Celery tasks in worker/celery_app.py
6. ‚úÖ Test Docker deployment
7. ‚úÖ Add health checks

**Deliverable**: Containerized deployment

**Estimated Effort**: 2-3 days

---

### MILESTONE 5: Fill Test Gaps (LOW PRIORITY)
**Goal**: 80%+ test coverage

**Tasks:**
1. ‚úÖ Add Phase 1 tests (ingestion/ASR)
2. ‚úÖ Add Phase 2 tests (segmentation/embeddings)
3. ‚úÖ Add Phase 3 tests (planning/writing)
4. ‚úÖ Add Phase 4 tests (RAG audit)
5. ‚úÖ Add Phase 6 tests (exporters)
6. ‚úÖ Add Phase 7 tests (QC)
7. ‚úÖ Run full test suite, fix failures

**Deliverable**: Comprehensive test suite

**Estimated Effort**: 3-4 days

---

### MILESTONE 6: Add Multilingual (FUTURE)
**Goal**: Phase 8 complete

**Tasks:**
1. ‚úÖ Install NLLB-200
2. ‚úÖ Implement translator.py
3. ‚úÖ Add multilingual voice configs
4. ‚úÖ Update TTS for language switching
5. ‚úÖ Test with non-English content

**Deliverable**: Multilingual support

**Estimated Effort**: 2 days

---

## CRITICAL PATH TO MVP

**To get a working MVP (v0.1):**

```
Week 1: Audio Pipeline
‚îú‚îÄ Day 1-2: Install Whisper, test transcription
‚îú‚îÄ Day 3-4: Install TTS (F5 or Piper), test synthesis
‚îî‚îÄ Day 5: Install ffmpeg, implement mixing

Week 2: Embeddings & Integration
‚îú‚îÄ Day 1-2: Install embeddings, FAISS, Qdrant
‚îú‚îÄ Day 3: Implement RAG retrieval
‚îú‚îÄ Day 4-5: End-to-end testing

Week 3: Polish & Deploy
‚îú‚îÄ Day 1-2: Write wrapper script, README
‚îú‚îÄ Day 3-4: Docker deployment
‚îî‚îÄ Day 5: Final testing, MVP release
```

**Total Effort**: ~3 weeks for functional MVP

---

## IMMEDIATE NEXT STEPS

### Step 1: Install Critical Dependencies
```bash
# ASR
pip install faster-whisper

# Audio
pip install ffmpeg-python pyloudnorm

# Embeddings
pip install sentence-transformers faiss-cpu

# Vector DB
docker run -d -p 6333:6333 qdrant/qdrant

# TTS (choose one)
# Option A: Piper (simpler)
wget https://github.com/rhasspy/piper/releases/download/v1.2.0/piper_amd64.tar.gz
# Option B: F5-TTS (better quality)
git clone https://github.com/SWivid/F5-TTS && cd F5-TTS && pip install -e .
```

### Step 2: Replace Mocks
Priority order:
1. **transcriber.py** - Add Whisper
2. **synthesizer.py** - Add TTS engine
3. **mixer.py** - Add real ffmpeg
4. **embedder.py** - Add sentence-transformers
5. **source_indexer.py** - Add Qdrant

### Step 3: Test End-to-End
```bash
# Place test audio in inputs/
cp test.mp3 inputs/

# Run pipeline
make ingest JOB=test_001
make outline JOB=test_001
make assemble JOB=test_001
make qc JOB=test_001

# Verify output
ls dist/export/test_001/
# Should contain: output_mix.mp3, notes.md, qc_report.json, feed.xml
```

---

## CURRENT LIMITATIONS

### What You CANNOT Do Yet
‚ùå Process real audio (no Whisper)
‚ùå Generate real speech (no TTS)
‚ùå Mix actual audio (no ffmpeg)
‚ùå Semantic search (no embeddings)
‚ùå RAG grounding (no Qdrant)
‚ùå API access (no FastAPI)
‚ùå Async processing (no Celery)
‚ùå Multilingual (Phase 8)

### What You CAN Do Now
‚úÖ Generate scripts with 10 personas
‚úÖ Create outlines with 3 length modes
‚úÖ Extract promo clips
‚úÖ Package stems for Clipchamp
‚úÖ Run QC checks (mock metrics)
‚úÖ Generate RSS feeds
‚úÖ Create export manifests

---

## ARCHITECTURE STRENGTHS

### What's Well-Designed
‚úÖ **Modular pipeline** - Each phase independent
‚úÖ **Config-driven** - No hardcoded values
‚úÖ **Persona system** - Unlimited extensibility
‚úÖ **Schema validation** - Type safety
‚úÖ **QC framework** - Comprehensive checks
‚úÖ **Export variants** - Multiple formats

### What Needs Improvement
‚ö†Ô∏è **Mock implementations** - Replace with real
‚ö†Ô∏è **Test coverage** - Only ~30%
‚ö†Ô∏è **Error handling** - Basic try/catch
‚ö†Ô∏è **Logging** - Minimal
‚ö†Ô∏è **Performance** - No optimization
‚ö†Ô∏è **Documentation** - Incomplete

---

## CONCLUSION

### Summary
Alexandria is **70% complete** with solid architecture and modular design. The framework is in place, but most AI/audio operations are mocked.

### To Ship MVP
**Focus on Milestone 1-3**: Install real dependencies, replace mocks, test end-to-end.

### Estimated Timeline
- **Functional MVP**: 3 weeks
- **Production-ready**: 6-8 weeks
- **V1 with multilingual**: 10-12 weeks

### Risk Assessment
üî¥ **High Risk**: TTS/ASR integration complexity
üü° **Medium Risk**: Docker deployment issues
üü¢ **Low Risk**: Config/persona system (already solid)

---

**Next Action**: Choose TTS engine (F5 vs Piper) and install dependencies.
